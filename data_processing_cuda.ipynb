{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737117ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "print('Import success! \\nReady to go!')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "with open('config/params_server.yaml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "params_extract = config['extract']\n",
    "params_learn = config['learn']\n",
    "params_paths = config['paths']\n",
    "params_ctrl = config['ctrl']\n",
    "\n",
    "params_paths\n",
    "# params_extract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca05bbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 加载 Train csv 数据\n",
    "train_csv = pd.read_csv(params_paths['train_csv'])\n",
    "train_csv.head()\n",
    "\n",
    "# 1.2 加载 test csv 数据\n",
    "test_csv = pd.read_csv(params_paths['test_csv'])\n",
    "test_csv.head()\n",
    "\n",
    "# 2.1 提取人类验证过的标注数据\n",
    "# get positions of manually_verified clips: separate between CLEAN and NOISY sets\n",
    "train_file_verified_list_col = train_csv.manually_verified.values.tolist()\n",
    "clean_set = [i for i, x in enumerate(train_file_verified_list_col) if x == 1]\n",
    "noisy_set = [i for i, x in enumerate(train_file_verified_list_col) if x == 0]\n",
    "\n",
    "\n",
    "# 2.2 分离干净/噪声数据（行索引\n",
    "clean_idx = train_csv[train_csv['manually_verified'] == 1].index  # 干净数据索引\n",
    "noisy_idx = train_csv[train_csv['manually_verified'] == 0].index  # 噪声数据索引\n",
    "\n",
    "# 3. 提取噪声样本ID (从文件名提取数字部分)\n",
    "noisy_ids = [int(fname.split('.')[0]) for fname in train_csv.loc[noisy_idx, 'fname']]\n",
    "print(f'\\nnoisy ids:{noisy_ids}')\n",
    "\n",
    "clean_ids = [int(fname.split('.')[0]) for fname in train_csv.loc[clean_idx, 'fname']]\n",
    "\n",
    "\n",
    "# 4. 创建标签映射\n",
    "labels = sorted(train_csv['label'].unique())    # 所有标签（按字母顺序）（唯一）\n",
    "label_to_int = {label: i for i, label in enumerate(labels)} # 标签到数字的映射\n",
    "int_to_label = {i: label for label, i in label_to_int.items()}\n",
    "\n",
    "# 5. 创建文件路径到标签的映射\n",
    "file_to_label = {\n",
    "    f\"{params_paths['train_audio_input']}/{row.fname}\": row.label \n",
    "    for _, row in train_csv.iterrows()\n",
    "}\n",
    "\n",
    "# 6. 创建文件路径到数字标签的映射\n",
    "file_to_int = {\n",
    "    path: label_to_int[label] \n",
    "    for path, label in file_to_label.items()\n",
    "}\n",
    "\n",
    "# 打印检查\n",
    "print(f\"干净数据数量: {len(clean_idx)}\")\n",
    "print(f\"噪声数据数量: {len(noisy_idx)}\")\n",
    "print(f\"标签映射示例: {label_to_int}\")\n",
    "print(f\"前5个文件标签: {list(file_to_label.items())[:5]}\")\n",
    "file_to_int\n",
    "file_to_label\n",
    "label_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dea42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 4. 创建标签映射\n",
    "test_labels = sorted(test_csv['label'].unique())    # 所有标签（按字母顺序）（唯一）\n",
    "test_label_to_int = {label: i for i, label in enumerate(test_labels)} # 标签到数字的映射\n",
    "test_int_to_label = {i: label for label, i in test_label_to_int.items()}\n",
    "\n",
    "# 5. 创建文件路径到标签的映射\n",
    "test_file_to_label = {\n",
    "    f\"{params_paths['test_audio_input']}/{row.fname}\": row.label \n",
    "    for _, row in test_csv.iterrows()\n",
    "}\n",
    "\n",
    "# 6. 创建文件路径到数字标签的映射\n",
    "test_file_to_int = {\n",
    "    path: test_label_to_int[label] \n",
    "    for path, label in test_file_to_label.items()\n",
    "}\n",
    "print(f\"标签映射示例: {test_label_to_int}\")\n",
    "print(f\"前5个文件标签: {list(test_file_to_label.items())[:5]}\")\n",
    "\n",
    "test_file_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febc97a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e758dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mel 频谱图的生成\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from feat_ext import load_audio_file, modify_file_variable_length, get_mel_spectrogram\n",
    "import utils\n",
    "\n",
    "\n",
    "\n",
    "def extract_features(input_dir, output_dir, force_reprocess=False):\n",
    "    \"\"\"\n",
    "    使用原作者的工具函数提取特征\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    audio_files = [f for f in os.listdir(input_dir) if f.endswith('.wav')]\n",
    "    # print(audio_files)\n",
    "    \n",
    "    # 检查 .data 结尾的文件，存在则替换成 .wav，检查其他还未处理的数据\n",
    "    if not force_reprocess:\n",
    "        existing_features = {f.replace('_mel.data', '.wav') for f in os.listdir(output_dir) if f.endswith('_mel.data')}\n",
    "        files_to_process = [f for f in audio_files if f not in existing_features]\n",
    "    else:\n",
    "        files_to_process = audio_files\n",
    "\n",
    "    if not files_to_process:\n",
    "        print(\"所有特征文件已存在，无需处理\")\n",
    "        return\n",
    "    \n",
    "    pbar = tqdm(files_to_process, desc=\"Extracting features\")\n",
    "    \n",
    "    for fname in pbar:\n",
    "        try:\n",
    "            audio_path = os.path.join(input_dir, fname)\n",
    "            # print(audio_path)\n",
    "            # 使用原作者的音频加载函数\n",
    "            y = load_audio_file(audio_path, \n",
    "                              input_fixed_length=params_extract['audio_len_s'],\n",
    "                              params_extract=params_extract)\n",
    "            # print(audio_path)\n",
    "            # print(f\"Loaded audio shape: {y.shape}\")  # 打印加载的音频形状\n",
    "\n",
    "            # 使用原作者的长度调整函数\n",
    "            y = modify_file_variable_length(y,\n",
    "                                         input_fixed_length=params_extract['audio_len_s'],\n",
    "                                         params_extract=params_extract)\n",
    "            # print(audio_path)\n",
    "            # 使用原作者的梅尔频谱计算函数\n",
    "            mel_spec = get_mel_spectrogram(y, params_extract)\n",
    "            # print(audio_path)\n",
    "            # print(f\"Mel spectrogram shape: {mel_spec.shape}\")  # 打印梅尔频谱图的形状\n",
    "            # print()\n",
    "\n",
    "            output_path = os.path.join(output_dir, fname.replace('.wav', '.data'))\n",
    "            utils.save_tensor(var=mel_spec, \n",
    "                            out_path=output_path, \n",
    "                            suffix='_mel')\n",
    "            # print(audio_path)\n",
    "\n",
    "\n",
    "            # 保存标签 - 使用file_to_int获取正确的标签索引\n",
    "            if 'test' in audio_path:\n",
    "                # print(audio_path, 'test in audio')\n",
    "                label_idx = test_file_to_int[audio_path]\n",
    "            else:\n",
    "                label_idx = file_to_int[audio_path]  # 从映射字典获取标签索引\n",
    "                \n",
    "            # print(audio_path)\n",
    "            utils.save_tensor(var=np.array([label_idx], dtype=float),\n",
    "                            out_path=output_path,\n",
    "                            suffix='_label')\n",
    "            # print(audio_path)\n",
    "            pbar.set_postfix({'status': f'Processed {fname}'})\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nError processing {fname}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "# 输入输出路径配置\n",
    "input_dirs = [\n",
    "    (params_paths['test_audio_input'], params_paths['test_feature_extracted']),  # (输入目录, 输出目录)\n",
    "    (params_paths['train_audio_input'], params_paths['train_feature_extracted']),  # (输入目录, 输出目录)\n",
    "]\n",
    "\n",
    "# 处理所有输入目录\n",
    "for input_dir, output_dir in input_dirs:\n",
    "    print(f\"\\nStarting feature extraction from {input_dir} to {output_dir}\")\n",
    "    extract_features(input_dir, output_dir, force_reprocess=False)\n",
    "    print(f\"Feature extraction from {input_dir} completed!\")\n",
    "\n",
    "print(\"\\nAll feature extraction tasks finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f900aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# mel_spec_test_path = \"./features/audio_test_varup2\"     # (输入目录, 输出目录)\n",
    "# mel_spec_train_path = \"./features/audio_train_varup2\"    # (输入目录, 输出目录)\n",
    "\n",
    "# dataset = 'FSDnoisy18k'\n",
    "# train_dataset_path = ./fsd18kdataset/FSDnoisy18k.audio_train\n",
    "# test_dataset_path =./fsd18kdataset/FSDnoisy18k.audio_test\n",
    "# train_csv_path =./fsd18kdataset/FSDnoisy18k.meta/train.csv\n",
    "# test_csv_path =./fsd18kdataset/FSDnoisy18k.meta/test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a432655",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 设置特征目录\n",
    "feature_dir = params_paths['test_feature_extracted']\n",
    "\n",
    "# 获取前5个特征文件\n",
    "data_files = [f for f in os.listdir(feature_dir) if f.endswith('_mel.data')][:20]\n",
    "\n",
    "# 读取并打印特征和标签\n",
    "for data_file in data_files:\n",
    "    # 构建完整路径\n",
    "    base_path = os.path.join(feature_dir, data_file.replace('_mel.data', ''))\n",
    "    \n",
    "    # 读取特征\n",
    "    features = utils.load_tensor(base_path + '.data', suffix='_mel')\n",
    "    \n",
    "    # 读取标签\n",
    "    labels = utils.load_tensor(base_path + '.data', suffix='_label')\n",
    "    \n",
    "    print(f\"\\n文件: {data_file}\")\n",
    "    print(f\"特征形状: {features.shape}, 数据类型: {features.dtype}\")\n",
    "    print(f\"标签值: {labels}\")\n",
    "    print(\"特征数据片段:\")\n",
    "    print(features[:2, :5])  # 打印前2帧的前5个特征值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f98e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "from data import DataGeneratorPatch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "\n",
    "class TorchDataWrapper(Dataset):\n",
    "    def __init__(self, keras_data_gen):\n",
    "        self.keras_gen = keras_data_gen\n",
    "        # self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.keras_gen)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        features, labels = self.keras_gen[idx]\n",
    "        return (\n",
    "            # torch.from_numpy(features).float().to(self.device),\n",
    "            # torch.from_numpy(labels.argmax(1)).long().to(self.device),\n",
    "            torch.from_numpy(features).float(),\n",
    "            torch.from_numpy(labels.argmax(1)).long()\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 初始化数据生成器\n",
    "feature_dir = params_paths['train_feature_extracted']\n",
    "file_list = [f for f in os.listdir(feature_dir) if f.endswith('_mel.data')]\n",
    "\n",
    "\n",
    "\n",
    "print(f\"wenjianliebiao:{file_list},\\n 特征文件数量: {len(file_list)}\\n\")\n",
    "data_gen = DataGeneratorPatch(\n",
    "    feature_dir=feature_dir,\n",
    "    file_list=file_list,\n",
    "    params_learn=params_learn,\n",
    "    params_extract=params_extract,\n",
    "    suffix_in='_mel',\n",
    "    suffix_out='_label'\n",
    ")\n",
    "\n",
    "# 创建PyTorch兼容的数据集\n",
    "torch_dataset = TorchDataWrapper(data_gen)\n",
    "\n",
    "# 创建PyTorch DataLoader\n",
    "train_loader = DataLoader(\n",
    "    torch_dataset,\n",
    "    batch_size=None,  # 因为原作者已处理批次\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "# 获取并打印第一个batch\n",
    "for batch_idx, (features, labels) in enumerate(train_loader):\n",
    "    features = features.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    print(f\"\\nPyTorch DataLoader 第一个batch:\")\n",
    "    print(f\"特征张量形状: {features.shape}\")  # 应该是 [batch, 1, time, freq]\n",
    "    print(f\"标签张量形状: {labels.shape}\")    # 应该是 [batch]\n",
    "    \n",
    "    # 打印第一个样本的部分数据\n",
    "    print(\"\\n第一个样本的特征数据(部分):\")\n",
    "    print(features[0, 0, :5, :5])  # 打印第一个样本的5x5片段\n",
    "    \n",
    "    print(\"\\n所有样本的标签:\")\n",
    "    print(labels)\n",
    "    \n",
    "    break  # 只查看第一个batch\n",
    "\n",
    "for batch_idx, (features, labels) in enumerate(train_loader):\n",
    "    print(f\"\\nPyTorch DataLoader 第一个batch:\")\n",
    "    print(f\"特征张量形状: {features.shape}\")  # [batch, 1, time, freq]\n",
    "    print(f\"标签张量形状: {labels.shape}\")    # [batch]\n",
    "    for i in range(features.shape[0]):\n",
    "        print(f\"\\n样本{i} 标签: {labels[i].item()}\")\n",
    "        print(f\"样本{i} 特征片段:\\n{features[i, 0, :5, :5]}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f606bb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseline_cnn import BaselineCNN\n",
    "from torch import nn\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "print(\"BaselineCNN imported successfully!\")\n",
    "model = BaselineCNN(\n",
    "    n_mels=params_extract['n_mels'],\n",
    "    patch_len=params_extract['patch_len'],\n",
    "    n_classes=params_learn['n_classes']\n",
    ").to(device)\n",
    "\n",
    "# 添加模型权重加载功能\n",
    "pretrained_path = params_paths['pretrained']  # 替换为你的预训练模型路径\n",
    "if os.path.exists(pretrained_path):\n",
    "    model.load_state_dict(torch.load(pretrained_path))\n",
    "    print('成功加载预训练权重')\n",
    "else:\n",
    "    print('未找到预训练模型，将从零开始训练')\n",
    "\n",
    "\n",
    "print('loading optimizer and loss function...')\n",
    "# 定义优化器和损失函数\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-3  # L2正则化\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='max',  # 监控验证准确率\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "\n",
    "# 添加检查点恢复功能\n",
    "checkpoint_path = 'interrupted_checkpoint.pth'\n",
    "start_epoch = 0\n",
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    best_acc = checkpoint['best_acc']\n",
    "    print(f'从检查点恢复训练，epoch={start_epoch}, 最佳准确率={best_acc:.4f}')\n",
    "\n",
    "\n",
    "# 创建TensorBoard writer\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# 训练循环\n",
    "def train(model, loader, optimizer, criterion, epochs=160):\n",
    "    model.train()\n",
    "    best_acc = 0.0\n",
    "\n",
    "    # 添加检查点目录\n",
    "    os.makedirs('checkpoints', exist_ok=True)\n",
    "\n",
    "    # 添加epoch进度条\n",
    "    epoch_pbar = tqdm(range(epochs), desc='Training', unit='epoch')\n",
    "\n",
    "    for epoch in epoch_pbar:\n",
    "        try:\n",
    "            total_loss = 0\n",
    "            correct = 0\n",
    "            # 添加batch进度条\n",
    "            batch_pbar = tqdm(loader, desc=f'Epoch {epoch+1}', leave=False)\n",
    "            for features, labels in batch_pbar:\n",
    "                features = features.to(device)\n",
    "                labels = labels.to(device)\n",
    "    \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # 前向传播\n",
    "                outputs = model(features)\n",
    "                loss = criterion(outputs, labels.squeeze())\n",
    "                \n",
    "                # 反向传播\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # 统计\n",
    "                total_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                correct += (predicted == labels.squeeze()).sum().item()\n",
    "\n",
    "                # 更新batch进度条\n",
    "                batch_pbar.set_postfix(loss=loss.item())\n",
    "            \n",
    "            # 计算epoch统计\n",
    "            avg_loss = total_loss / len(loader)\n",
    "            accuracy = correct / len(loader.dataset)\n",
    "\n",
    "             # 记录到TensorBoard\n",
    "            writer.add_scalar('Loss/train', avg_loss, epoch)\n",
    "            writer.add_scalar('Accuracy/train', accuracy, epoch)\n",
    "\n",
    "            # 更新学习率\n",
    "            scheduler.step(accuracy)\n",
    "\n",
    "            # 保存最佳模型\n",
    "            if accuracy > best_acc:\n",
    "                best_acc = accuracy\n",
    "                torch.save(model.state_dict(), 'best_model.pth')\n",
    "                print(f'保存最佳模型，准确率: {accuracy:.4f}')\n",
    "            print(f'Epoch {epoch+1}: Loss={avg_loss:.4f}, Accuracy={accuracy:.4f}')\n",
    "\n",
    "            # 更新epoch进度条\n",
    "            epoch_pbar.set_postfix(loss=avg_loss, acc=accuracy)\n",
    "\n",
    "            # # 保存检查点(每个epoch都保存)\n",
    "            # checkpoint_path = f'checkpoints/epoch_{epoch+1}.pth'\n",
    "            # torch.save({\n",
    "            #     'epoch': epoch+1,\n",
    "            #     'model_state_dict': model.state_dict(),\n",
    "            #     'optimizer_state_dict': optimizer.state_dict(),\n",
    "            #     'best_acc': best_acc,\n",
    "            #     'loss': avg_loss,\n",
    "            # }, checkpoint_path)\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n训练被中断，正在保存当前状态...\")\n",
    "            torch.save({\n",
    "                'epoch': epoch+1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_acc': best_acc,\n",
    "                'loss': avg_loss,\n",
    "            }, 'interrupted_checkpoint.pth')\n",
    "            print(\"已保存中断检查点到 interrupted_checkpoint.pth\")\n",
    "            return\n",
    "\n",
    "    # 训练结束后保存最终模型\n",
    "    # torch.save(model.state_dict(), 'final_model.pth')\n",
    "    # print('训练完成，最终模型已保存')\n",
    "    writer.close()\n",
    "    torch.save(model.state_dict(), 'final_model.pth')\n",
    "    epoch_pbar.write('训练完成，最终模型已保存')\n",
    "\n",
    "print('training started...')\n",
    "\n",
    "# 开始训练\n",
    "train(model, train_loader, optimizer, criterion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
